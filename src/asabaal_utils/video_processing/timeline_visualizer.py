import matplotlib.pyplot as plt
import numpy as np
import json
import argparse
import os
from typing import List, Dict, Any


def load_analysis_report(report_path: str) -> Dict:
    """Load the analysis report generated by the VideoTimelineAnalyzer."""
    with open(report_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def format_time(seconds: float) -> str:
    """Format seconds as MM:SS safely."""
    try:
        minutes = int(float(seconds) // 60)
        secs = int(float(seconds) % 60)
        return f"{minutes:02d}:{seconds:02d}"
    except (ValueError, TypeError):
        # Return a placeholder if seconds is not a valid number
        return "00:00"


def truncate_text(text: str, max_length: int = 40) -> str:
    """Truncate text to a maximum length."""
    if not text:
        return ""
    if len(text) <= max_length:
        return text
    return text[:max_length - 3] + "..."


def visualize_video_coverage(report: Dict, output_file: str = None, dpi: int = 300, 
                           figsize: tuple = (14, 10), show_clip_labels: bool = True):
    """
    Create a visual representation of video coverage across the timeline.
    
    Args:
        report: Analysis report from VideoTimelineAnalyzer
        output_file: Path to save the output image (if None, displays the plot)
        dpi: Resolution for the output image
        figsize: Size of the figure (width, height) in inches
        show_clip_labels: Whether to show clip names on the timeline
    """
    # Extract data from the report
    timeline_segments = report.get('timeline_segments', [])
    timeline_start = report.get('timeline_start', 0)
    timeline_end = report.get('timeline_end', 0)
    timeline_duration = report.get('timeline_duration', 0)
    video_clips = report.get('video_clips', [])
    uncovered_regions = report.get('uncovered_regions', [])
    
    # Create a figure with multiple subplots
    fig = plt.figure(figsize=figsize)
    gs = fig.add_gridspec(4, 1, height_ratios=[1, 3, 2, 2], hspace=0.4)
    
    # 1. Timeline summary plot (shows a high-level view of coverage)
    ax_summary = fig.add_subplot(gs[0, 0])
    
    # 2. Video clips visualization (shows each video clip)
    ax_clips = fig.add_subplot(gs[1, 0])
    
    # 3. Uncovered regions visualization
    ax_uncovered = fig.add_subplot(gs[2, 0])
    
    # 4. Statistics and information
    ax_stats = fig.add_subplot(gs[3, 0])
    
    # Add a title to the figure
    fig.suptitle('CapCut Video Coverage Analysis', fontsize=16, y=0.98)
    
    # Colors for different segment types
    colors = {
        'covered': '#4CAF50',    # Green for covered segments
        'uncovered': '#F44336',  # Red for uncovered segments
    }
    
    # --- TIMELINE SUMMARY PLOT ---
    # Plot a summary view that shows covered vs uncovered segments
    covered_segments = []
    uncovered_segments = []
    
    for segment in timeline_segments:
        if segment['has_video']:
            covered_segments.append((segment['start_time'], segment['duration']))
        else:
            uncovered_segments.append((segment['start_time'], segment['duration']))
    
    # Plot covered segments
    if covered_segments:
        ax_summary.broken_barh(
            covered_segments,
            (0, 1),
            facecolors=colors['covered'],
            edgecolors='darkgreen',
            linewidth=0.5,
            alpha=0.7
        )
    
    # Plot uncovered segments
    if uncovered_segments:
        ax_summary.broken_barh(
            uncovered_segments,
            (0, 1),
            facecolors=colors['uncovered'],
            edgecolors='darkred',
            linewidth=0.5,
            alpha=0.7
        )
    
    # Format the summary timeline
    ax_summary.set_xlim(timeline_start, timeline_end)
    ax_summary.set_ylim(0, 1)
    ax_summary.set_yticks([])
    ax_summary.set_title('Timeline Video Coverage Overview', fontsize=14)
    ax_summary.grid(axis='x', alpha=0.3)
    
    # Add time markers
    time_interval = max(1, int(timeline_duration / 10))  # At least 10 markers
    time_ticks = np.arange(timeline_start, timeline_end + 1, time_interval)
    ax_summary.set_xticks(time_ticks)
    ax_summary.set_xticklabels([f"{int(t//60):02d}:{int(t%60):02d}" for t in time_ticks])
    
    # --- VIDEO CLIPS VISUALIZATION ---
    # Show each video clip as a bar
    # Sort clips by track and start time
    sorted_video_clips = sorted(video_clips, key=lambda x: (x.get('track_index', 0), x['start_time']))
    
    # Group clips by track for visualization
    tracks = {}
    for clip in sorted_video_clips:
        track_idx = clip.get('track_index', 0)
        if track_idx not in tracks:
            tracks[track_idx] = []
        tracks[track_idx].append(clip)
    
    # Plot each track of video clips
    y_pos = 0
    track_labels = []
    
    for track_idx, track_clips in sorted(tracks.items()):
        track_labels.append(f"Track {track_idx}")
        
        # Plot each clip in this track
        for clip in track_clips:
            # Extract clip details for visualization
            start_time = clip['start_time']
            duration = clip['duration']
            clip_name = os.path.basename(clip.get('material_name', 'Clip')) if clip.get('material_name') else 'Clip'
            
            # Plot the clip
            ax_clips.broken_barh(
                [(start_time, duration)],
                (y_pos, 0.8),
                facecolors=colors['covered'],
                edgecolors='black',
                linewidth=0.5,
                alpha=0.8
            )
            
            # Add clip label if enabled
            if show_clip_labels and duration > timeline_duration / 50:  # Only show labels for clips wide enough
                ax_clips.text(
                    start_time + duration/2,
                    y_pos + 0.4,
                    truncate_text(clip_name, 25),
                    ha='center',
                    va='center',
                    fontsize=8,
                    rotation=0 if duration > timeline_duration / 20 else 90,
                    color='black'
                )
        
        # Move to next track
        y_pos += 1
    
    # Set up the clips axis
    ax_clips.set_xlim(timeline_start, timeline_end)
    ax_clips.set_ylim(0, max(1, len(tracks)))
    ax_clips.set_yticks([i + 0.4 for i in range(len(tracks))])
    ax_clips.set_yticklabels(track_labels)
    ax_clips.set_title('Video Clips by Track', fontsize=14)
    ax_clips.grid(axis='x', alpha=0.3)
    ax_clips.set_xticks(time_ticks)
    ax_clips.set_xticklabels([f"{int(t//60):02d}:{int(t%60):02d}" for t in time_ticks])
    
    # --- UNCOVERED REGIONS VISUALIZATION ---
    # Show uncovered regions with any lyrics in them
    if uncovered_regions:
        regions_with_lyrics = [region for region in uncovered_regions if region.get('lyrics')]
        regions_without_lyrics = [region for region in uncovered_regions if not region.get('lyrics')]
        
        y_pos = 0
        region_labels = []
        
        # First plot regions with lyrics (more important)
        for i, region in enumerate(regions_with_lyrics):
            start_time = region['start_time']
            duration = region['duration']
            
            # Count lyrics in this region
            lyrics_count = len(region.get('lyrics', []))
            
            ax_uncovered.broken_barh(
                [(start_time, duration)],
                (y_pos, 0.8),
                facecolors=colors['uncovered'],
                edgecolors='black',
                linewidth=0.5,
                alpha=0.8
            )
            
            # Add region label
            label = f"Region {i+1}: {lyrics_count} lyrics"
            region_labels.append(label)
            
            # Add timestamp info
            start_str = f"{int(start_time//60):02d}:{int(start_time%60):02d}"
            end_str = f"{int((start_time+duration)//60):02d}:{int((start_time+duration)%60):02d}"
            
            ax_uncovered.text(
                start_time + duration/2,
                y_pos + 0.4,
                f"{start_str} - {end_str}",
                ha='center',
                va='center',
                fontsize=8,
                color='white'
            )
            
            y_pos += 1
        
        # Then plot regions without lyrics (less important)
        for i, region in enumerate(regions_without_lyrics):
            start_time = region['start_time']
            duration = region['duration']
            
            ax_uncovered.broken_barh(
                [(start_time, duration)],
                (y_pos, 0.5),  # Make these shorter
                facecolors='lightcoral',  # Lighter color
                edgecolors='black',
                linewidth=0.5,
                alpha=0.5
            )
            
            # Add region label
            label = f"Empty Region {i+1}"
            region_labels.append(label)
            
            y_pos += 1
        
        # Set up the uncovered regions axis
        ax_uncovered.set_xlim(timeline_start, timeline_end)
        ax_uncovered.set_ylim(0, max(1, y_pos))
        ax_uncovered.set_yticks([i + 0.4 for i in range(len(region_labels))])
        ax_uncovered.set_yticklabels(region_labels)
        ax_uncovered.set_title('Uncovered Timeline Regions', fontsize=14)
        ax_uncovered.grid(axis='x', alpha=0.3)
        ax_uncovered.set_xticks(time_ticks)
        ax_uncovered.set_xticklabels([f"{int(t//60):02d}:{int(t%60):02d}" for t in time_ticks])
    else:
        # No uncovered regions
        ax_uncovered.text(
            0.5, 0.5,
            "No uncovered regions found! Full video coverage.",
            ha='center', va='center',
            fontsize=14, color='green',
            transform=ax_uncovered.transAxes
        )
        ax_uncovered.set_title('Uncovered Timeline Regions', fontsize=14)
        ax_uncovered.set_xticks([])
        ax_uncovered.set_yticks([])
    
    # --- STATISTICS DISPLAY ---
    # Hide axes for the stats display
    ax_stats.axis('off')
    
    # Calculate statistics
    covered_duration = report.get('covered_duration', 0)
    uncovered_duration = report.get('uncovered_duration', 0)
    video_coverage_percentage = report.get('video_coverage_percentage', 0)
    
    # Create a text summary
    covered_min = int(covered_duration // 60)
    covered_sec = int(covered_duration % 60)
    uncovered_min = int(uncovered_duration // 60)
    uncovered_sec = int(uncovered_duration % 60)
    total_min = int(timeline_duration // 60)
    total_sec = int(timeline_duration % 60)
    
    stats_text = (
        f"Timeline Coverage Summary\n"
        f"------------------------\n"
        f"Total Timeline Duration: {total_min:02d}:{total_sec:02d} ({timeline_duration:.1f}s)\n"
        f"Covered by Video: {covered_min:02d}:{covered_sec:02d} ({covered_duration:.1f}s) - {video_coverage_percentage:.1f}%\n"
        f"Uncovered Areas: {uncovered_min:02d}:{uncovered_sec:02d} ({uncovered_duration:.1f}s) - {100-video_coverage_percentage:.1f}%\n\n"
        f"Video Clips: {len(video_clips)} clips across {len(tracks)} tracks\n"
        f"Uncovered Regions: {len(uncovered_regions)} regions"
    )
    
    # Add the text to the figure
    ax_stats.text(
        0.01, 0.95, stats_text,
        va='top', ha='left',
        fontsize=12,
        family='monospace'
    )
    
    # Create a legend for the colors
    from matplotlib.patches import Patch
    legend_elements = [
        Patch(facecolor=colors['covered'], edgecolor='black', label='Covered (Has Video)'),
        Patch(facecolor=colors['uncovered'], edgecolor='black', label='Uncovered (No Video)'),
        Patch(facecolor='lightcoral', edgecolor='black', label='Empty Uncovered (No Lyrics, No Video)')
    ]
    ax_stats.legend(handles=legend_elements, loc='center right', frameon=True)
    
    # Adjust layout
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    
    # Save or display the plot
    if output_file:
        plt.savefig(output_file, dpi=dpi, bbox_inches='tight')
        print(f"Video coverage visualization saved to {output_file}")
    else:
        plt.show()


def generate_uncovered_regions_report(report: Dict, output_file: str = None):
    """
    Generate a detailed report of uncovered timeline regions.
    
    Args:
        report: Analysis report from VideoTimelineAnalyzer
        output_file: Path to save the output report (if None, prints to console)
    """
    # Extract uncovered regions
    uncovered_regions = report.get('uncovered_regions', [])
    
    # Sort by start time
    uncovered_regions = sorted(uncovered_regions, key=lambda x: x['start_time'])
    
    # Format the report
    report_content = "# Uncovered Timeline Regions Report\n\n"
    
    if not uncovered_regions:
        report_content += "No uncovered regions found! Your timeline has full video coverage.\n"
    else:
        report_content += f"Found {len(uncovered_regions)} uncovered regions with no video coverage:\n\n"
        
        for i, region in enumerate(uncovered_regions):
            # Format start and end times
            start_min = int(region['start_time'] // 60)
            start_sec = int(region['start_time'] % 60)
            end_min = int(region['end_time'] // 60)
            end_sec = int(region['end_time'] % 60)
            
            report_content += f"## Region {i+1}: {start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d} ({region['duration']:.1f}s)\n\n"
            
            lyrics = region.get('lyrics', [])
            
            if lyrics:
                # Sort lyrics by start time
                sorted_lyrics = sorted(lyrics, key=lambda x: x['start_time'])
                
                report_content += f"Contains {len(lyrics)} lyrics that need video coverage:\n\n"
                
                for lyric in sorted_lyrics:
                    lyric_start_min = int(lyric['start_time'] // 60)
                    lyric_start_sec = int(lyric['start_time'] % 60)
                    lyric_end_min = int(lyric['end_time'] // 60)
                    lyric_end_sec = int(lyric['end_time'] % 60)
                    
                    report_content += f"- {lyric_start_min:02d}:{lyric_start_sec:02d} - {lyric_end_min:02d}:{lyric_end_sec:02d}: {lyric['text']}\n"
            else:
                report_content += "No lyrics in this region.\n"
            
            report_content += "\n"
    
    # Save or print the report
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        print(f"Uncovered regions report saved to {output_file}")
    else:
        print(report_content)


def generate_clip_details_report(report: Dict, output_file: str = None):
    """
    Generate a detailed report of all video clips in the timeline.
    
    Args:
        report: Analysis report from VideoTimelineAnalyzer
        output_file: Path to save the output report (if None, prints to console)
    """
    # Extract video clips
    video_clips = report.get('video_clips', [])
    
    # Sort by track and then by start time
    video_clips = sorted(video_clips, key=lambda x: (x.get('track_index', 0), x['start_time']))
    
    # Format the report
    report_content = "# Video Clips Details Report\n\n"
    
    if not video_clips:
        report_content += "No video clips found in the timeline.\n"
    else:
        report_content += f"Found {len(video_clips)} video clips in the timeline:\n\n"
        
        # Group by track
        tracks = {}
        for clip in video_clips:
            track_idx = clip.get('track_index', 0)
            if track_idx not in tracks:
                tracks[track_idx] = []
            tracks[track_idx].append(clip)
        
        for track_idx, track_clips in sorted(tracks.items()):
            report_content += f"## Track {track_idx}\n\n"
            
            for i, clip in enumerate(track_clips):
                # Format start and end times
                start_min = int(clip['start_time'] // 60)
                start_sec = int(clip['start_time'] % 60)
                end_min = int(clip['end_time'] // 60)
                end_sec = int(clip['end_time'] % 60)
                
                clip_name = os.path.basename(clip.get('material_path', '')) if clip.get('material_path') else 'Unnamed Clip'
                
                report_content += f"### Clip {i+1}: {clip_name}\n\n"
                report_content += f"- **Time**: {start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d} ({clip['duration']:.1f}s)\n"
                report_content += f"- **Type**: {clip.get('type', 'Unknown')}\n"
                
                # If we have material path details
                if clip.get('material_path'):
                    report_content += f"- **Source**: {clip['material_path']}\n"
                
                report_content += "\n"
    
    # Save or print the report
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        print(f"Video clips details report saved to {output_file}")
    else:
        print(report_content)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Visualize video coverage in CapCut timeline")
    parser.add_argument("--report", required=True, help="Path to analysis report JSON file")
    parser.add_argument("--output", help="Output image file path (PNG/JPG/PDF)")
    parser.add_argument("--uncovered-report", help="Output file for uncovered regions report")
    parser.add_argument("--clip-details", help="Output file for detailed clip information report")
    parser.add_argument("--dpi", type=int, default=300, help="DPI for output image")
    parser.add_argument("--no-clip-labels", action="store_true", help="Hide clip labels on the timeline")
    
    args = parser.parse_args()
    
    try:
        report = load_analysis_report(args.report)
        
        # Generate the timeline visualization
        visualize_video_coverage(
            report, 
            args.output, 
            dpi=args.dpi,
            show_clip_labels=not args.no_clip_labels
        )
        
        # Generate uncovered regions report if requested
        if args.uncovered_report:
            generate_uncovered_regions_report(report, args.uncovered_report)
        
        # Generate clip details report if requested
        if args.clip_details:
            generate_clip_details_report(report, args.clip_details)
            
    except Exception as e:
        print(f"Error: {str(e)}")
        import traceback
        traceback.print_exc()